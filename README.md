# Nishtha Lath (ë‹ˆìŠ¤íƒ€)

**Computer Science & Engineering Student** | Kyungpook National University  
**Focus:** AI Systems Â· LLM Applications Â· Full-Stack Development Â· Research

I build AI-driven systems that solve real problemsâ€”from conversational interfaces for accessible kiosks to RAG-based disaster response tools. My work combines research depth with production deployment experience.

---

## Experience

**Frontend Developer Intern (Team Leader)** | RikkeiSoft Corporation  
*Dec 2024 â€“ Jan 2025*

Led frontend development for an internal AI chatbot platform serving employees, administrators, and clients. Architected the entire React/TypeScript UI with role-based dashboards, prompt customization, and file management systems.

**Undergraduate Lab Intern** | Intelligent Software Systems Lab, KNU  
*Oct 2025 â€“ Dec 2025*

Built RAG-based disaster response assistant integrating legal manuals, population data, and geospatial risk information. Implemented FAISS vector store with LangChain pipelines and optimized FastAPI backend for fast, context-aware decision support.

---

## Research

**Evaluating LLaMA Model for Enhanced Conversational AI in Voice Recognition Kiosks**  
UCWIT 2024 (KIISE) Â· **ğŸ† Excellent Paper Award** (Top 4 / 47 teams)

Comparative analysis demonstrating LLaMA's superiority over rule-based frameworks (RASA) in handling ambiguous, multi-intent conversational input for real-world kiosk environments.

---

## Selected Projects

**[SheBots â€“ AI-Integrated RAG Chatbot](https://github.com/NishthaLath/SheBots)**  
Production-deployed department information assistant using GPT-4.1, FAISS, and LangChain. Solved complex deployment challenges including AWS EC2 configuration, Docker containerization, and NGINX reverse proxy setup.

**[AI-Driven Voice Recognition Cafe Kiosk](https://github.com/AI-coffee-Kiosk)**  
Accessibility-focused ordering system using fine-tuned LLaMA models with Unsloth. Handles complex multi-item orders through advanced prompt engineering and deployed via Hugging Face Hub.

**[Visioned â€“ Accessible Public Transportation Kiosk](https://github.com/VISIONED-KNU)**  
Voice-driven navigation system for elderly users integrating Google Cloud APIs (STT, TTS, Maps) with Node.js backend and React frontend. Human-centered design with route optimization.

**[AI-Based Multi-CCTV Person Detection & Behavior Analysis](https://github.com/NishthaLath/AI-CCTV)**  
Surveillance system combining YOLO + DeepSORT for tracking, ST-GCN for action recognition, and FaceNet + OSNet for cross-camera re-identification.

---

## Technical Skills

**Languages:** Python Â· Java Â· JavaScript Â· C Â· C++  
**AI/ML:** LLaMA Â· GPT Â· RAG Â· LangChain Â· FAISS Â· PyTorch Â· Transformers Â· Prompt Engineering  
**Web:** React.js Â· TypeScript Â· FastAPI Â· Spring Boot Â· Node.js Â· Tailwind CSS  
**Infrastructure:** Docker Â· NGINX Â· AWS EC2 Â· RESTful APIs  
**Computer Vision:** YOLO Â· DeepSORT Â· MediaPipe Â· ST-GCN Â· OpenCV  
**Languages:** English (Fluent) Â· Hindi (Native) Â· Korean (Advanced, TOPIK 5)

---

## Recognition

- **Global Korea Scholarship** (2022â€“2026) â€“ Full undergraduate scholarship
- **UCWIT 2024 Excellent Paper Award** â€“ Top 4 / 47 teams
- **International Student Representative** â€“ CS Department, KNU
- **KERT Cybersecurity Club** â€“ CTF competitions, web security

---

## Connect

ğŸ“§ lathnishtha775@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/nishtha-lath-335206276/)  
ğŸ“„ [Resume (English)](Resume%20(Lath%20Nishtha).pdf) Â· [ì´ë ¥ì„œ (Korean)](ì´ë ¥ì„œ_ë‹ˆìŠ¤íƒ€(2022427833).pdf)

**Location:** Daegu, South Korea Â· **GPA:** 3.55/4.3
